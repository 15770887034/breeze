[
    {
        "variable": "AddWorkerNodesOnly",
        "label": "Just add new worker nodes, do not reinstall this cluster",
        "description": "Existing master nodes will not be updated. Please install docker for new worker nodes at first.",
        "type": "bool",
        "default": "false",
        "required": true
    },
    {
        "variable": "UpgradeCluster",
        "label": "Upgrade existing cluster",
        "description": "Existing master/worker nodes will be upgraded. Please backup etcd at first.",
        "type": "bool",
        "default": "false",
        "required": true
    },
    {
        "variable": "AutoUpgradeK8sNodes",
        "label": "Upgrade K8s nodes automatically",
        "description": "All master and worker nodes will be upgraded automatically. During the upgrade process, worker nodes are cordoned and drained.",
        "type": "bool",
        "default": "true",
        "required": true
    },
    {
        "variable": "master",
        "label": "Kubernetes master nodes",
        "description": "hosts to be set up as kubernetes master nodes",
        "type": "host",
        "required": false
    },
    {
        "variable": "worker",
        "label": "Kubenetes worker nodes",
        "description": "hosts to be set up as kubernetes worker nodes",
        "type": "host",
        "required": false
    },
    {
        "variable": "endpoint",
        "label": "Kubernetes entry point",
        "description": "IP:port of kubernetes cluster entrypoint (e.g. 192.168.1.100:6444)",
        "type": "string",
        "default": "",
        "required": false
    },
    {
        "variable": "cni",
        "label": "Kubernetes cni component mode",
        "description": "Flannel | Calico | Canal",
        "type": "enum",
        "default": "Flannel",
        "required": true,
        "options": [ "Flannel", "Calico", "Canal" ]
    },
    {
        "variable": "pod_cidr",
        "label": "Kubernetes pod CIDR",
        "description": "Pod CIDR  (e.g. 10.244.0.0/16)",
        "type": "string",
        "default": "10.244.0.0/16",
        "required": true
    },
    {
        "variable": "cluster_cidr",
        "label": "Kubernetes kubeproxy clusterIP CIDR",
        "description": "ClusterIP CIDR  (e.g. 10.244.0.0/16)",
        "type": "string",
        "default": "10.244.0.0/16",
        "required": true
    },
    {
        "variable": "service_cidr",
        "label": "Kubernetes service CIDR",
        "description": "Kubernetes service CIDR  (e.g. 10.96.0.0/12)",
        "type": "string",
        "default": "10.96.0.0/12",
        "required": true
    },
    {
        "variable": "calico_nodes",
        "label": "Number of Calico nodes",
        "description": "50_nodes_or_less | More_than_50_nodes",
        "type": "enum",
        "default": "More_than_50_nodes",
        "required": true,
        "options": [ "50_nodes_or_less", "More_than_50_nodes" ]
    },
    {
        "variable": "calico_typha_replicas",
        "label": "Desired number of replicas for calico-typha deployment",
        "description": "Recommend at least one replica for every 200 nodes and no more than 20 replicas. In production, we recommend a minimum of three replicas to reduce the impact of rolling upgrades and failures. The number of replicas should always be less than the number of nodes, otherwise rolling upgrades will stall.",
        "type": "int",
        "default": "3",
        "required": true
    }
]
